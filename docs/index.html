<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based High-Performance GPU Kernel Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>QiMeng-Kernel</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- highlight code -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    img {
      transition: all 0.3s ease;
      border-radius: 8px;
    }

    .result-image:hover {
      box-shadow: 0 8px 25px rgba(0, 0, 0, 0.2);
      cursor: pointer;
    }

    .bibtex-container {
      position: relative;
      background-color: #f5f5f5;
      border-radius: 8px;
      padding: 1rem;
      box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }

    pre {
      background-color: transparent !important;
      padding: 0 !important;
      margin: 0 !important;
      white-space: pre-wrap;
    }

    .copy-btn {
      position: absolute;
      top: 10px;
      right: 10px;
      background-color: #fff;
      border: 1px solid #dbdbdb;
      border-radius: 4px;
      padding: 5px 10px;
      font-size: 0.8rem;
      cursor: pointer;
      transition: all 0.2s;
      color: #4a4a4a;
    }

    .copy-btn:hover {
      background-color: #363636;
      color: #fff;
      border-color: #363636;
    }

    .copy-btn.copied {
      background-color: #48c774;
      color: white;
      border-color: #48c774;
    }

    .result-card {
      background: white;
      padding: 1.5rem;
      border-radius: 12px;
      box-shadow: 0 4px 10px rgba(0,0,0,0.05);
      margin-bottom: 2rem;
    }
    
    .result-caption {
      font-weight: 600;
      font-size: 1.1rem;
      margin-bottom: 1rem;
      color: #363636;
    }
  </style>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based
              High-Performance GPU Kernel Generation</h1>

            <div class="is-size-5 publication-authors" style="margin-top: 1.5rem;">
              <span class="author-block">
                <a>Xinguo Zhu</a><sup>1,3,4</sup>,</span>
              <span class="author-block">
                <a>Shaohui Peng</a><sup>1,4</sup>,</span>
              <span class="author-block">
                <a>Jiaming Guo</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a>Yunji Chen</a><sup>2,4</sup>,
              </span>
              <span class="author-block">
                <a>Qi Guo</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a>Yuanbo Wen</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a>Hang Qin</a><sup>1,3,4</sup>,
              </span>
              <span class="author-block">
                <a>Ruizhi Chen</a><sup>1,4</sup>,
              </span>
              <span class="author-block">
                <a>Qirui Zhou</a><sup>2,4</sup>,
              </span>
              <span class="author-block">
                <a>Ke Gao</a><sup>1,4</sup>,
              </span>
              <span class="author-block">
                <a>Yanjun Wu</a><sup>1,4</sup>,
              </span>
              <span class="author-block">
                <a>Chen Zhao</a><sup>1,4</sup>,
              </span>
              <span class="author-block">
                <a>Ling Li</a><sup>1,4</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors" style="margin-top: 1rem; margin-bottom: 2rem; font-size: 0.9rem !important;">
              <span class="author-block"><sup>1</sup>Intelligent Software Research Center, Institute of Software, CAS,
                Beijing, China</span><br>
              <span class="author-block"><sup>2</sup>State Key Lab of Processors, Institute of Computing Technology,
                CAS, Beijing, China</span><br>
              <span class="author-block"><sup>3</sup>Hangzhou Institute for Advanced Study, UCAS, Hangzhou,
                China</span><br>
              <span class="author-block"><sup>4</sup>University of Chinese Academy of Sciences</span><br>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2511.20100" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/AKatydid/QiMeng-Kernel"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3" style="margin-bottom: 2rem;">Overview</h2>
          
          <div class="box has-background-light" style="box-shadow: none; background-color: #fcfcfc;">
            <div class="content has-text-justified">
              Developing high-performance GPU kernels is critical for AI and scientific computing, but remains challenging
              due to its reliance on expert crafting and poor portability. While LLMs offer promise for automation, both
              general-purpose and finetuned LLMs suffer from two fundamental and conflicting limitations: correctness and
              efficiency. The key reason is that existing LLM-based approaches directly generate the entire optimized
              low-level programs, requiring exploration of an extremely vast space encompassing both optimization policies
              and implementation codes.
              <br /><br />
              To address the challenge of exploring an intractable space, we propose <strong>Macro Thinking Micro Coding (MTMC)</strong>, a
              hierarchical framework inspired by the staged optimization strategy of human experts. It decouples
              optimization strategy from implementation details, ensuring efficiency through high-level strategy and
              correctness through low-level implementation. Specifically, Macro Thinking employs reinforcement learning to
              guide lightweight LLMs in efficiently exploring and learning semantic optimization strategies that maximize
              hardware utilization. Micro Coding leverages general-purpose LLMs to incrementally implement the stepwise
              optimization proposals from Macro Thinking, avoiding full-kernel generation errors. Together, they
              effectively navigate the vast optimization space and intricate implementation details, enabling LLMs for
              high-performance GPU kernel generation. 
              <br /><br />
              Comprehensive results on widely adopted benchmarks demonstrate the
              superior performance of MTMC on GPU kernel generation in both accuracy and running time. On KernelBench,
              MTMC achieves near 100% and 70% accuracy at Levels 1-2 and 3, over 50% than SOTA general-purpose and
              domain-finetuned LLMs, with up to 7.3x speedup over LLMs, and 2.2x over expert-optimized PyTorch Eager
              kernels. On the more challenging TritonBench, MTMC attains up to 59.64% accuracy and 34x speedup.
            </div>
          </div>

          <div class="has-text-centered" style="margin: 3rem 0;">
            <img src="./static/images/overview.png" class="result-image" style="max-width: 100%; height: auto;">
          </div>
          <div class="content has-text-justified is-size-6">
            <p style="line-height: 1.6; color: #555;">
              <strong>Figure 1:</strong> The overview of MTMC framework. The framework takes unoptimized PyTorch code as input and generates
              high-performance GPU kernels with hierarchical process: Macro Thinking generates semantic optimization
              actions, while Micro Coding implements them step-by-step. The optimization policy based on lightweight
              LLMs is trained with RL on compact human-craft dataset.
            </p>
          </div>
        </div>
      </div>
      <!--/ Overview. -->
    </div>
  </section>

  <section class="section" style="background-color: #fefefe;">
    <!-- Results -->
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3" style="margin-bottom: 2.5rem;">Results</h2>
          
          <!-- Result 1 -->
          <div class="result-card">
            <div class="result-caption">Results on KernelBench</div>
            <div class="has-text-centered">
              <img src="./static/images/result-kernelbenchv0.png" class="result-image">
            </div>
          </div>

          <!-- Result 2 -->
          <div class="result-card">
            <div class="result-caption">Results on TritonBench</div>
            <div class="has-text-centered">
              <img src="./static/images/result-tritonbench.png" class="result-image">
            </div>
          </div>

        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered" style="margin-bottom: 2rem;">Citation</h2>
          
          <div class="bibtex-container">
            <button class="copy-btn" onclick="copyBibtex()">
              <span class="icon is-small">
                <i class="far fa-copy"></i>
              </span>
              <span>Copy</span>
            </button>
            <pre><code class="language-bibtex" id="bibtex-content">@article{zhu2025qimeng,
  title={QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based High-Performance GPU Kernel Generation},
  author={Zhu, Xinguo and Peng, Shaohui and Guo, Jiaming and Chen, Yunji and Guo, Qi and Wen, Yuanbo and Qin, Hang and Chen, Ruizhi and Zhou, Qirui and Gao, Ke and others},
  journal={arXiv preprint arXiv:2511.20100},
  year={2025}
}</code></pre>
          </div>

        </div>
      </div>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content has-text-centered">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              Thanks for the website template <a href="https://nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- JavaScript for Copy Functionality -->
  <script>
    function copyBibtex() {
      const bibtexContent = document.getElementById('bibtex-content').innerText;
      navigator.clipboard.writeText(bibtexContent).then(() => {
        const btn = document.querySelector('.copy-btn');
        const originalText = btn.innerHTML;
        
        btn.classList.add('copied');
        btn.innerHTML = '<span class="icon is-small"><i class="fas fa-check"></i></span><span>Copied!</span>';
        
        setTimeout(() => {
          btn.classList.remove('copied');
          btn.innerHTML = '<span class="icon is-small"><i class="far fa-copy"></i></span><span>Copy</span>';
        }, 2000);
      }).catch(err => {
        console.error('Failed to copy text: ', err);
      });
    }
  </script>

</body>

</html>